{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Mood of the News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Dependencies\n",
    "import tweepy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "# Import and Initialize Sentiment Analyzer\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Twitter API Keys\n",
    "from config import (consumer_key, \n",
    "                    consumer_secret, \n",
    "                    access_token, \n",
    "                    access_token_secret)\n",
    "\n",
    "# Setup Tweepy API Authentication\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, parser=tweepy.parsers.JSONParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: @BBC\n",
      "Compound: 0.233\n",
      "Positive: 0.112\n",
      "Neutral: 0.869\n",
      "Negative: 0.020\n",
      "\n",
      "User: @CNN\n",
      "Compound: -0.100\n",
      "Positive: 0.035\n",
      "Neutral: 0.886\n",
      "Negative: 0.079\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Target Search Term\n",
    "target_user = (\"@BBC\", \"@CNN\")\n",
    "#\"@CNN\", \"@CBSNews\",\"@FoxNews\", \"@nytimes\"\n",
    "# Array to hold sentiment\n",
    "sentiment_array = []\n",
    "\n",
    "# A list to hold tweet timestamps\n",
    "tweet_times = []\n",
    "\n",
    "# Loop through all target users\n",
    "for target in target_user:\n",
    "\n",
    "    # Variable for holding the oldest tweet\n",
    "    oldest_tweet = None\n",
    "\n",
    "    # Variables for holding sentiments\n",
    "    compound_list = []\n",
    "    positive_list = []\n",
    "    negative_list = []\n",
    "    neutral_list = []\n",
    "    \n",
    "    # Loop through 5 pages of tweets (total 100 tweets)\n",
    "    for x in range(5):\n",
    "        \n",
    "        # Get all tweets from home feed\n",
    "        public_tweets = api.user_timeline(target, page=x)\n",
    "\n",
    "        # Loop through all tweets\n",
    "        for tweet in public_tweets:\n",
    "            \n",
    "            #Get the raw tweet time\n",
    "            raw_time = tweet[\"created_at\"]\n",
    "            tweet_times.append(raw_time)\n",
    "\n",
    "            # Run Vader Analysis on each tweet\n",
    "            results = analyzer.polarity_scores(tweet[\"text\"])\n",
    "            compound = results[\"compound\"]\n",
    "            pos = results[\"pos\"]\n",
    "            neu = results[\"neu\"]\n",
    "            neg = results[\"neg\"]\n",
    "            \n",
    "            # Add each value to the appropriate list\n",
    "            compound_list.append(compound)\n",
    "            positive_list.append(pos)\n",
    "            negative_list.append(neg)\n",
    "            neutral_list.append(neu)\n",
    "            \n",
    "    # Print the Averages\n",
    "    print(f\"User: {target}\")\n",
    "    print(f\"Compound: {np.mean(compound_list):.3f}\")\n",
    "    print(f\"Positive: {np.mean(positive_list):.3f}\")\n",
    "    print(f\"Neutral: {np.mean(neutral_list):.3f}\")\n",
    "    print(f\"Negative: {np.mean(negative_list):.3f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert tweet timestamps to datetime objects that can be manipulated by\n",
    "# Python\n",
    "converted_timestamps = []\n",
    "for raw_time in tweet_times:\n",
    "    # https://docs.python.org/3/library/datetime.html#strftime-and-strptime-behavior\n",
    "    # http://strftime.org/\n",
    "    converted_time = datetime.strptime(raw_time, \"%a %b %d %H:%M:%S %z %Y\")\n",
    "    converted_timestamps.append(converted_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-28 19:42:29+00:00\n",
      "2017-11-28 19:42:18+00:00\n",
      "2017-11-28 19:39:01+00:00\n",
      "2017-11-28 19:38:52+00:00\n",
      "2017-11-28 19:38:42+00:00\n",
      "2017-11-28 19:38:36+00:00\n",
      "2017-11-28 19:38:14+00:00\n",
      "2017-11-28 19:38:03+00:00\n",
      "2017-11-28 19:37:49+00:00\n",
      "2017-11-28 19:33:15+00:00\n",
      "2017-11-28 19:00:01+00:00\n",
      "2017-11-28 18:30:07+00:00\n",
      "2017-11-28 18:00:06+00:00\n",
      "2017-11-28 17:34:03+00:00\n",
      "2017-11-28 17:02:04+00:00\n",
      "2017-11-28 16:32:03+00:00\n",
      "2017-11-28 15:44:17+00:00\n",
      "2017-11-28 15:42:48+00:00\n",
      "2017-11-28 14:51:03+00:00\n",
      "2017-11-28 14:33:07+00:00\n",
      "2017-11-28 19:42:29+00:00\n",
      "2017-11-28 19:42:18+00:00\n",
      "2017-11-28 19:39:01+00:00\n",
      "2017-11-28 19:38:52+00:00\n",
      "2017-11-28 19:38:42+00:00\n",
      "2017-11-28 19:38:36+00:00\n",
      "2017-11-28 19:38:14+00:00\n",
      "2017-11-28 19:38:03+00:00\n",
      "2017-11-28 19:37:49+00:00\n",
      "2017-11-28 19:33:15+00:00\n",
      "2017-11-28 19:00:01+00:00\n",
      "2017-11-28 18:30:07+00:00\n",
      "2017-11-28 18:00:06+00:00\n",
      "2017-11-28 17:34:03+00:00\n",
      "2017-11-28 17:02:04+00:00\n",
      "2017-11-28 16:32:03+00:00\n",
      "2017-11-28 15:44:17+00:00\n",
      "2017-11-28 15:42:48+00:00\n",
      "2017-11-28 14:51:03+00:00\n",
      "2017-11-28 14:33:07+00:00\n",
      "2017-11-28 14:00:18+00:00\n",
      "2017-11-28 13:52:02+00:00\n",
      "2017-11-28 13:33:04+00:00\n",
      "2017-11-28 13:02:03+00:00\n",
      "2017-11-28 12:42:12+00:00\n",
      "2017-11-28 12:30:03+00:00\n",
      "2017-11-28 12:12:03+00:00\n",
      "2017-11-28 11:57:59+00:00\n",
      "2017-11-28 11:38:12+00:00\n",
      "2017-11-28 10:17:56+00:00\n",
      "2017-11-28 10:17:12+00:00\n",
      "2017-11-28 09:59:55+00:00\n",
      "2017-11-28 09:59:31+00:00\n",
      "2017-11-28 09:33:02+00:00\n",
      "2017-11-28 08:55:04+00:00\n",
      "2017-11-28 08:38:37+00:00\n",
      "2017-11-28 08:35:33+00:00\n",
      "2017-11-28 08:35:11+00:00\n",
      "2017-11-28 08:34:51+00:00\n",
      "2017-11-28 08:32:04+00:00\n",
      "2017-11-28 08:00:02+00:00\n",
      "2017-11-28 07:38:03+00:00\n",
      "2017-11-27 22:06:03+00:00\n",
      "2017-11-27 21:24:04+00:00\n",
      "2017-11-27 21:05:04+00:00\n",
      "2017-11-27 20:34:03+00:00\n",
      "2017-11-27 20:07:05+00:00\n",
      "2017-11-27 19:41:28+00:00\n",
      "2017-11-27 19:38:53+00:00\n",
      "2017-11-27 19:26:08+00:00\n",
      "2017-11-27 19:24:55+00:00\n",
      "2017-11-27 19:24:45+00:00\n",
      "2017-11-27 19:24:35+00:00\n",
      "2017-11-27 19:00:03+00:00\n",
      "2017-11-27 18:56:21+00:00\n",
      "2017-11-27 18:33:04+00:00\n",
      "2017-11-27 18:02:03+00:00\n",
      "2017-11-27 17:33:04+00:00\n",
      "2017-11-27 17:00:03+00:00\n",
      "2017-11-27 16:02:05+00:00\n",
      "2017-11-27 15:23:03+00:00\n",
      "2017-11-27 15:19:52+00:00\n",
      "2017-11-27 15:18:43+00:00\n",
      "2017-11-27 15:17:30+00:00\n",
      "2017-11-27 14:45:30+00:00\n",
      "2017-11-27 14:34:36+00:00\n",
      "2017-11-27 14:04:47+00:00\n",
      "2017-11-27 14:03:04+00:00\n",
      "2017-11-27 13:33:03+00:00\n",
      "2017-11-27 12:56:05+00:00\n",
      "2017-11-27 12:30:02+00:00\n",
      "2017-11-27 12:03:03+00:00\n",
      "2017-11-27 11:52:24+00:00\n",
      "2017-11-27 11:45:56+00:00\n",
      "2017-11-27 11:33:04+00:00\n",
      "2017-11-27 10:21:04+00:00\n",
      "2017-11-27 10:07:30+00:00\n",
      "2017-11-27 10:07:11+00:00\n",
      "2017-11-27 10:06:56+00:00\n",
      "2017-11-27 10:06:48+00:00\n",
      "2017-11-28 22:56:28+00:00\n",
      "2017-11-28 22:50:59+00:00\n",
      "2017-11-28 22:36:51+00:00\n",
      "2017-11-28 22:29:33+00:00\n",
      "2017-11-28 21:59:07+00:00\n",
      "2017-11-28 21:47:14+00:00\n",
      "2017-11-28 21:33:04+00:00\n",
      "2017-11-28 21:21:48+00:00\n",
      "2017-11-28 21:19:05+00:00\n",
      "2017-11-28 21:09:02+00:00\n",
      "2017-11-28 21:04:53+00:00\n",
      "2017-11-28 21:00:09+00:00\n",
      "2017-11-28 20:50:09+00:00\n",
      "2017-11-28 20:40:13+00:00\n",
      "2017-11-28 20:23:25+00:00\n",
      "2017-11-28 20:22:06+00:00\n",
      "2017-11-28 20:10:03+00:00\n",
      "2017-11-28 20:00:38+00:00\n",
      "2017-11-28 19:50:07+00:00\n",
      "2017-11-28 19:40:09+00:00\n",
      "2017-11-28 22:56:28+00:00\n",
      "2017-11-28 22:50:59+00:00\n",
      "2017-11-28 22:36:51+00:00\n",
      "2017-11-28 22:29:33+00:00\n",
      "2017-11-28 21:59:07+00:00\n",
      "2017-11-28 21:47:14+00:00\n",
      "2017-11-28 21:33:04+00:00\n",
      "2017-11-28 21:21:48+00:00\n",
      "2017-11-28 21:19:05+00:00\n",
      "2017-11-28 21:09:02+00:00\n",
      "2017-11-28 21:04:53+00:00\n",
      "2017-11-28 21:00:09+00:00\n",
      "2017-11-28 20:50:09+00:00\n",
      "2017-11-28 20:40:13+00:00\n",
      "2017-11-28 20:23:25+00:00\n",
      "2017-11-28 20:22:06+00:00\n",
      "2017-11-28 20:10:03+00:00\n",
      "2017-11-28 20:00:38+00:00\n",
      "2017-11-28 19:50:07+00:00\n",
      "2017-11-28 19:40:09+00:00\n",
      "2017-11-28 19:33:07+00:00\n",
      "2017-11-28 19:30:07+00:00\n",
      "2017-11-28 19:28:42+00:00\n",
      "2017-11-28 19:10:13+00:00\n",
      "2017-11-28 19:10:11+00:00\n",
      "2017-11-28 18:57:29+00:00\n",
      "2017-11-28 18:50:09+00:00\n",
      "2017-11-28 18:40:19+00:00\n",
      "2017-11-28 18:31:07+00:00\n",
      "2017-11-28 18:20:06+00:00\n",
      "2017-11-28 18:10:09+00:00\n",
      "2017-11-28 18:00:31+00:00\n",
      "2017-11-28 17:46:31+00:00\n",
      "2017-11-28 17:36:28+00:00\n",
      "2017-11-28 17:20:01+00:00\n",
      "2017-11-28 17:10:07+00:00\n",
      "2017-11-28 17:01:07+00:00\n",
      "2017-11-28 16:53:04+00:00\n",
      "2017-11-28 16:42:39+00:00\n",
      "2017-11-28 16:34:23+00:00\n",
      "2017-11-28 16:20:13+00:00\n",
      "2017-11-28 16:12:10+00:00\n",
      "2017-11-28 16:00:52+00:00\n",
      "2017-11-28 15:50:45+00:00\n",
      "2017-11-28 15:39:46+00:00\n",
      "2017-11-28 15:36:53+00:00\n",
      "2017-11-28 15:32:40+00:00\n",
      "2017-11-28 15:30:11+00:00\n",
      "2017-11-28 15:20:08+00:00\n",
      "2017-11-28 15:09:01+00:00\n",
      "2017-11-28 15:01:49+00:00\n",
      "2017-11-28 14:58:16+00:00\n",
      "2017-11-28 14:48:27+00:00\n",
      "2017-11-28 14:37:15+00:00\n",
      "2017-11-28 14:26:18+00:00\n",
      "2017-11-28 14:13:02+00:00\n",
      "2017-11-28 14:00:18+00:00\n",
      "2017-11-28 13:52:28+00:00\n",
      "2017-11-28 13:42:25+00:00\n",
      "2017-11-28 13:25:03+00:00\n",
      "2017-11-28 13:18:56+00:00\n",
      "2017-11-28 13:12:28+00:00\n",
      "2017-11-28 13:00:45+00:00\n",
      "2017-11-28 12:41:45+00:00\n",
      "2017-11-28 12:25:03+00:00\n",
      "2017-11-28 12:15:10+00:00\n",
      "2017-11-28 12:10:05+00:00\n",
      "2017-11-28 12:09:52+00:00\n",
      "2017-11-28 12:07:49+00:00\n",
      "2017-11-28 12:00:05+00:00\n",
      "2017-11-28 11:53:24+00:00\n",
      "2017-11-28 11:45:08+00:00\n",
      "2017-11-28 11:43:48+00:00\n",
      "2017-11-28 11:35:03+00:00\n",
      "2017-11-28 11:25:42+00:00\n",
      "2017-11-28 11:12:37+00:00\n",
      "2017-11-28 10:59:18+00:00\n",
      "2017-11-28 10:46:57+00:00\n",
      "2017-11-28 10:34:30+00:00\n",
      "2017-11-28 10:22:06+00:00\n"
     ]
    }
   ],
   "source": [
    "for tweet in converted_timestamps:\n",
    "    print(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "print(len(converted_timestamps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1. Need to get time stamps of the 100 tweets \"Tweets Ago\".\n",
    "#2. Need to put tweet in df with time stamp and the compound sentiment analysis. \n",
    "#3. Graph the 100 tweets from each news source with a timestamp \"Tweets Ago\". "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
